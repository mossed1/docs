import { Callout, Steps } from 'nextra/components'
import Image from 'next/image'

<Callout type="error" emoji="üö´">
TARS-AI is in the early stages of development. You may expect rapid changes to the platform.
</Callout>
<Callout type="warning" emoji="‚ö†Ô∏è">
May be out of date or incomplete. Always confirm on our [Discord](https://discord.gg/uXkqkz3mJJ) for the most up-to-date information.
</Callout>


# Software Setup
TARS-AI is powered by a **modular software stack** designed for real-time speech, vision, and motor control. Follow these instructions to install and set up the TARS-AI environment on your Raspberry Pi.

## Minimum Hardware Prerequisites
1. **Raspberry Pi**: Required for running the setup.
2. **USB Microphone**: For user input.
3. **Speaker**: For TARS output.

<Callout type="warning" emoji="‚ö†Ô∏è">
If you don't already have Raspberry Pi OS installed, follow [this video guide](https://www.youtube.com/watch?v=DRJAILbqjy0) to install Raspberry Pi OS using the Raspberry Pi Imager.
</Callout>

## Environment Setup and Installation

<Steps>

### Configure Raspberry Pi
1. Open a terminal and run:
   ```bash
   sudo raspi-config
   ```
2. Update the configuration tool through `Update`.
<Image src="/setup/setup_0.png" alt="Setup Image 0" width={1000} height={300} />
3. Under `Interface Options`, enable `VNC`, `SPI`, and `I2C`.
4. Set audio settings under `Advanced Options` ‚Üí `Audio Config` ‚Üí `Pipewire`.
5. Reboot the system:
   ```bash
   sudo reboot
   ```
   
<Callout type="default" emoji="‚öôÔ∏è">
  **Note:** If you need extended help, refer to the [Raspberry Pi I2C setup guide](https://www.raspberrypi.com/documentation/computers/raspberry-pi.html#i2c-bus).
</Callout>

### Install and Configure LCD-show
1. Clone and install the [LCD-show driver](https://github.com/goodtft/LCD-show):
   ```bash
   git clone https://github.com/goodtft/LCD-show.git
   cd LCD-show
   chmod +x LCD35-show
   sudo ./LCD35-show
   ```
<Callout type="info" emoji="‚ÑπÔ∏è">
This configures a **3.5-inch 480x320 LCD**.
</Callout>

2. Modify boot configuration for HDMI resolution with VNC:
   ```bash
   sudo nano /boot/config.txt
   ```
   Add or update:
   ```ini
   hdmi_force_hotplug=1
   hdmi_group=2
   hdmi_mode=82  # 1920x1080 resolution
   framebuffer_width=1920
   framebuffer_height=1080
   ```

3. Modify boot configuration for screen rotation:
   ```bash
   sudo nano /boot/config.txt
   ```
   Add:
   ```ini
   dtoverlay=tft35a:rotate=270
   ```

4. Restart the system:
   ```bash
   sudo reboot
   ```

### Touchscreen Calibration
1. Install the Calibration Tool
```bash
sudo apt-get install xinput-calibrator
```

2. Run the Calibration Tool
```bash
xinput_calibrator 
```
Touch the targets as instructed. The tool will generate calibration offsets.

3. Save the Calibration Data
Copy and Paste the calibration data and save the file. Save the output data to a configuration file:

```bash
sudo nano /usr/share/X11/xorg.conf.d/99-calibration.conf 
```

4. Reboot
```bash
sudo reboot
```

5. Verify Calibration
Interact with the desktop to ensure accurate touch. If needed, rerun the calibration tool or manually adjust the values in 99-calibration.conf.

### Clone the TARS-AI Repository
1. Open a terminal on your Raspberry Pi.
2. Clone the **TARS-AI** repository:
   ```bash
   sudo apt install python3-venv -y
   git clone https://github.com/TARS-AI-Community/TARS-AI
   ```
3. Navigate to the cloned directory:
   ```bash
   cd TARS-AI
   ```

### Install System Dependencies
To ensure smooth operation, use the included install script.

1. **Update your system**:
   ```bash
   sudo apt update
   sudo apt upgrade -y
   ```
2. **Update script permissions**:
   ```bash
   chmod 777 Install.sh
   ```
3. **Allow the script to be executable**:
   ```bash
   chmod a+x Install.sh
   ```
4. **Run the provided script**:
   ```bash
   sudo ./Install.sh
   ```

### Connect Hardware
1. **Microphone**: Plug a USB microphone into your Raspberry Pi.
2. **Speaker**: Connect an external speaker via **audio jack** or **Bluetooth**.


### Install Audio AMP
1. Edit the boot configuration file:
   ```bash
   nano /boot/config.txt
   ```

2. Add the following lines at the end of the file:
   ```ini
   dtparam=audio=on
   dtoverlay=hifiberry-dac
   dtoverlay=i2s-mmap
   ```

3. Install required dependencies and setup I2S amplifier from the TARS-AI Folder:
   ```bash
   source src/.venv/bin/activate
   sudo apt install -y wget
   pip3 install adafruit-python-shell
   wget https://github.com/adafruit/Raspberry-Pi-Installer-Scripts/raw/main/i2samp.py
   sudo -E env PATH=$PATH python3 i2samp.py
   ```

   **‚ö†Ô∏è DO NOT run audio in the background**, as it will break **VAD (Voice Activity Detection)** and **RMS (Root Mean Square) processing**.

4. Reboot the system:
   ```bash
   sudo reboot
   ```

5. After rebooting, activate the environment and re-run the setup script from the TARS-AI folder:
   ```bash
   source src/.venv/bin/activate (if not already activate)
   sudo -E env PATH=$PATH python3 i2samp.py
   ```

6. Test the speaker output:
   - When prompted, say **yes** to the speaker test and listen for sound.
   - If the audio sounds **distorted**, reduce the volume using `alsamixer`.

7. Enable volume control in **Raspbian Desktop** or **RetroPie**:
   - Reboot the system **again**:
     ```bash
     sudo reboot
     ```
   - After the second reboot, open `alsamixer`:
     ```bash
     alsamixer
     ```
   - Use the **arrow keys** to lower the volume (50% is a good starting point).

8. If audio issues persist:
   - Re-run the `i2samp.py` script.
   - When prompted, choose **N (disable)** for the `/dev/zero` playback service.

### Configure API Keys
To enable **LLM** and **TTS** functionality, configure your API keys.

1. Edit the `.env` file and replace `"your-actual-api-key"` with your valid keys:
   ```env
   # LLM API Keys
   OPENAI_API_KEY="your-actual-openai-api-key"
   OOBA_API_KEY="your-actual-ooba-api-key"
   TABBY_API_KEY="your-actual-tabby-api-key"

   # TTS API Keys
   AZURE_API_KEY="your-actual-azure-api-key"
   ```

**Get Your API Keys:**
- [OpenAI API Key](https://www.youtube.com/watch?v=OB99E7Y1cMA)
- [Azure Speech API Key (FREE)](https://www.youtube.com/watch?v=e4_AytZ264Q)
    - Make sure to create a Free Azure account [Free Azure Signup](https://azure.microsoft.com/en-us/pricing/purchase-options/azure-account?icid=azurefreeaccount)
    - Follow all the steps in the video up to `Install Azure speech Python package`.

### Set Up Configuration Parameters
1. Open `src/config.ini` and update the **LLM settings**:
   ```ini
   [LLM]
   llm_backend = openai
   base_url = https://api.openai.com
   openai_model = gpt-4o-mini
   ```
2. Update the **TTS (Text-to-Speech) settings**:
   ```ini
   [TTS]
   ttsoption = azure
   azure_region = eastus
   tts_voice = en-US-Steffan:DragonHDLatestNeural
   ```

### Run the Program
1. Navigate to the source directory:
   ```bash
   cd src/
   ```
2. Start the **TARS-AI assistant**:
   ```bash
   python app.py
   ```
3. TARS-AI is now running! Speak into the microphone and listen to responses from the speaker.

</Steps>

---

## (Optional) Home Assistant Integration
<Steps>
TARS-AI can integrate with **Home Assistant** to enable **smart home automation** via voice commands.

The **Home Assistant integration** allows TARS to:
- **Process voice commands** and trigger smart home actions.
- **Interact with connected devices** (lights, thermostats, security systems, etc.).
- **Leverage Home Assistant's Assistant API** to send prompts and execute actions.

To enable this integration, **TARS-AI must be configured** to communicate with your **Home Assistant server**.

### Prerequisites
Before setting up integration, ensure:
1. **Home Assistant is installed** and running on your local network.
2. **TARS-AI is fully set up** on your Raspberry Pi.
3. **A Home Assistant long-lived access token** is generated.

### Configure Home Assistant in `config.ini`
1. **Open `src/config.ini`** and locate the `[HOME_ASSISTANT]` section.
2. Enable the Home Assistant module and configure the connection URL:
   ```ini
   [HOME_ASSISTANT] # HA Module
   enabled = True
   # If set to False, the Home Assistant module will be disabled.
   url = http://homeassistant.local:8123
   # Example: http://192.168.2.5:8123
   # URL to access Home Assistant (set Token in .env file!).
   ```
3. Adjust the **URL** if your Home Assistant is running on a different address.

### Generate and Add the Access Token
TARS-AI needs a **long-lived access token** to authenticate with Home Assistant.

1. **Log into Home Assistant**.
2. Click on your **User Profile** (bottom left corner).
3. Scroll down to the **Security** section.
4. Locate **"Long-lived access tokens"** and click **"Create Token"**.
5. Enter a name for your token and click **OK**.
6. **Copy the token immediately**, as it won't be visible again.

### Store the Access Token in `.env`
1. Open the `.env` file in your TARS-AI directory.
2. Add your **Home Assistant Token**:
   ```env
   HA_TOKEN="INSERT-YOUR-TOKEN-HERE"
   ```
3. Save the file.

### Restart TARS-AI to Apply Changes

1. Navigate to the `src/` directory:
   ```bash
   cd src/
   ```
2. Restart the application:
   ```bash
   python app.py
   ```
</Steps>

Now, TARS-AI can **control smart home devices** with voice commands! üé§üè†

## Next Steps
Now that you've connected to your TARS-AI for the first time, it's time for [testing and your first run](/build/run).

---

<Callout type="default" emoji="üëâ">
  **Documentation Contributors:** @alexander-wang03, @pyrater
</Callout>

